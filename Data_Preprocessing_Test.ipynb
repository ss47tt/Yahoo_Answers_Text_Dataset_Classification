{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9                       What makes friendship click?  \\\n",
      "0  2                      Why does Zebras have stripes?   \n",
      "1  4           What did the itsy bitsy sipder climb up?   \n",
      "2  4  What is the difference between a Bachelors and...   \n",
      "3  3                              Why do women get PMS?   \n",
      "4  3  If your co-worker is guilty of unsanitary hygi...   \n",
      "\n",
      "                      How does the spark keep going?  \\\n",
      "0  What is the purpose or those stripes? Who do t...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "  good communication is what does it.  Can you move beyond small talk and say what's really on your mind.  If you start doing this, my expereince is that potentially good friends will respond or shun you.  Then you know who the really good friends are.  \n",
      "0  this provides camouflage - predator vision is ...                                                                                                                                                                                                          \n",
      "1                                         waterspout                                                                                                                                                                                                          \n",
      "2  One difference between a Bachelors and a Maste...                                                                                                                                                                                                          \n",
      "3  Premenstrual syndrome (PMS) is a group of symp...                                                                                                                                                                                                          \n",
      "4  Yes, it is your obligation. Especially if it i...                                                                                                                                                                                                          \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV (adjust delimiter if needed)\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset has column names, replace with actual names\n",
    "df.columns = [\"Class\", \"Title\", \"Content\", \"Answer\"]\n",
    "\n",
    "# Combine title and content into a single text field\n",
    "df[\"text\"] = df[\"Title\"].fillna('') + \" \" + df[\"Content\"].fillna('') + \" \" + df[\"Answer\"].fillna('')\n",
    "\n",
    "# Keep only the relevant columns\n",
    "df = df[[\"Class\", \"text\"]]\n",
    "\n",
    "# Convert class labels to zero-based indexing (optional)\n",
    "df[\"Class\"] = df[\"Class\"] - 1  # Convert from 1-10 to 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from contractions import fix\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Ensure the text is not empty or just whitespace\n",
    "    if not text or text.isspace():\n",
    "        return \"\"  # Return an empty string if the input is invalid\n",
    "    \n",
    "    try:\n",
    "        # Expand contractions (e.g., \"don't\" -> \"do not\")\n",
    "        text = fix(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error expanding contractions: {e} for text: {text}\")\n",
    "        return text  # Return original text if an error occurs\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Tokenize, remove stopwords, and lemmatize\n",
    "    text = \" \".join(lemmatizer.lemmatize(word.strip()) for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the function to the dataset\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "df.to_csv(\"preprocessed_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_test.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"preprocessed_test.csv\")\n",
    "\n",
    "# Ensure columns exist\n",
    "if \"text\" not in df.columns or \"Class\" not in df.columns:\n",
    "    raise ValueError(\"Columns 'text' and 'Class' not found in the CSV file.\")\n",
    "\n",
    "# Drop rows with NaN values in both 'text' and 'Class' columns\n",
    "df = df.dropna(subset=[\"text\", \"Class\"])\n",
    "\n",
    "# Extract features and labels\n",
    "X = df[\"text\"]  # Text data\n",
    "y = df[\"Class\"]  # Target labels\n",
    "\n",
    "# Initialize the vectorizer after data cleaning\n",
    "vectorizer = TfidfVectorizer(max_features=100000)\n",
    "\n",
    "# Proceed with TF-IDF vectorization\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Save the TF-IDF vectorizer model\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "Accuracy: 0.6766127687947991\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56       603\n",
      "           1       0.75      0.71      0.73       612\n",
      "           2       0.69      0.81      0.75       627\n",
      "           3       0.63      0.37      0.46       591\n",
      "           4       0.77      0.85      0.81       586\n",
      "           5       0.90      0.78      0.84       605\n",
      "           6       0.58      0.51      0.54       587\n",
      "           7       0.78      0.56      0.65       634\n",
      "           8       0.52      0.86      0.65       576\n",
      "           9       0.66      0.79      0.72       578\n",
      "\n",
      "    accuracy                           0.68      5999\n",
      "   macro avg       0.69      0.68      0.67      5999\n",
      "weighted avg       0.69      0.68      0.67      5999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Load the pre-trained TF-IDF vectorizers for train data\n",
    "vectorizer_train = joblib.load(\"tfidf_vectorizer_test.pkl\")\n",
    "\n",
    "# Load the preprocessed training dataset\n",
    "df_train = pd.read_csv(\"preprocessed_test.csv\")\n",
    "\n",
    "# Ensure the 'text' and 'Class' columns exist\n",
    "if \"text\" not in df_train.columns or \"Class\" not in df_train.columns:\n",
    "    raise ValueError(\"Columns 'text' and 'Class' not found in the train CSV file.\")\n",
    "\n",
    "# Drop rows with NaN values in both 'text' and 'Class' columns\n",
    "df_train = df_train.dropna(subset=[\"text\", \"Class\"])\n",
    "\n",
    "# Extract features and labels for training data\n",
    "X_train = df_train[\"text\"]  # Train data text\n",
    "y_train = df_train[\"Class\"]  # Train data labels\n",
    "\n",
    "# Split the training data into a training set and validation set (e.g., 90% train, 10% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=None)\n",
    "\n",
    "# Transform the training and validation data using the corresponding vectorizer\n",
    "X_train_tfidf = vectorizer_train.transform(X_train)\n",
    "X_val_tfidf = vectorizer_train.transform(X_val)\n",
    "\n",
    "# Initialize the model (e.g., Naive Bayes)\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training data (X_train_tfidf and y_train)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "print(\"Validation Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results:\n",
      "Accuracy: 0.6766127687947991\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56       603\n",
      "           1       0.75      0.71      0.73       612\n",
      "           2       0.69      0.81      0.75       627\n",
      "           3       0.63      0.37      0.46       591\n",
      "           4       0.77      0.85      0.81       586\n",
      "           5       0.90      0.78      0.84       605\n",
      "           6       0.58      0.51      0.54       587\n",
      "           7       0.78      0.56      0.65       634\n",
      "           8       0.52      0.86      0.65       576\n",
      "           9       0.66      0.79      0.72       578\n",
      "\n",
      "    accuracy                           0.68      5999\n",
      "   macro avg       0.69      0.68      0.67      5999\n",
      "weighted avg       0.69      0.68      0.67      5999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Using Logistic Regression for text classification\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
