{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9                       What makes friendship click?  \\\n",
      "0  2                      Why does Zebras have stripes?   \n",
      "1  4           What did the itsy bitsy sipder climb up?   \n",
      "2  4  What is the difference between a Bachelors and...   \n",
      "3  3                              Why do women get PMS?   \n",
      "4  3  If your co-worker is guilty of unsanitary hygi...   \n",
      "\n",
      "                      How does the spark keep going?  \\\n",
      "0  What is the purpose or those stripes? Who do t...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "  good communication is what does it.  Can you move beyond small talk and say what's really on your mind.  If you start doing this, my expereince is that potentially good friends will respond or shun you.  Then you know who the really good friends are.  \n",
      "0  this provides camouflage - predator vision is ...                                                                                                                                                                                                          \n",
      "1                                         waterspout                                                                                                                                                                                                          \n",
      "2  One difference between a Bachelors and a Maste...                                                                                                                                                                                                          \n",
      "3  Premenstrual syndrome (PMS) is a group of symp...                                                                                                                                                                                                          \n",
      "4  Yes, it is your obligation. Especially if it i...                                                                                                                                                                                                          \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV (adjust delimiter if needed)\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset has column names, replace with actual names\n",
    "df.columns = [\"Class\", \"Title\", \"Content\", \"Answer\"]\n",
    "\n",
    "# Combine title and content into a single text field\n",
    "df[\"text\"] = df[\"Title\"].fillna('') + \" \" + df[\"Content\"].fillna('') + \" \" + df[\"Answer\"].fillna('')\n",
    "\n",
    "# Keep only the relevant columns\n",
    "df = df[[\"Class\", \"text\"]]\n",
    "\n",
    "# Convert class labels to zero-based indexing (optional)\n",
    "df[\"Class\"] = df[\"Class\"] - 1  # Convert from 1-10 to 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from contractions import fix  # Install using: pip install contractions\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Ensure the text is not empty or just whitespace\n",
    "    if not text or text.isspace():\n",
    "        return \"\"  # Return an empty string if the input is invalid\n",
    "    \n",
    "    try:\n",
    "        # Expand contractions (e.g., \"don't\" -> \"do not\")\n",
    "        text = fix(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error expanding contractions: {e} for text: {text}\")\n",
    "        return text  # Return original text if an error occurs\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Tokenize, remove stopwords, and lemmatize\n",
    "    text = \" \".join(lemmatizer.lemmatize(word.strip()) for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the function to the dataset\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "df.to_csv(\"preprocessed_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_test.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"preprocessed_test.csv\")\n",
    "\n",
    "# Ensure columns exist\n",
    "if \"text\" not in df.columns or \"Class\" not in df.columns:\n",
    "    raise ValueError(\"Columns 'text' and 'Class' not found in the CSV file.\")\n",
    "\n",
    "# Drop rows with NaN values in both 'text' and 'Class' columns\n",
    "df = df.dropna(subset=[\"text\", \"Class\"])\n",
    "\n",
    "# Extract features and labels\n",
    "X = df[\"text\"]  # Text data\n",
    "y = df[\"Class\"]  # Target labels\n",
    "\n",
    "# Initialize the vectorizer after data cleaning\n",
    "vectorizer = TfidfVectorizer(max_features=100000)\n",
    "\n",
    "# Proceed with TF-IDF vectorization\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Save the TF-IDF vectorizer model\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
