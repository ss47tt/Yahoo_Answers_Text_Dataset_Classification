{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5 why doesn't an optical mouse work on a glass table?  \\\n",
      "0  6       What is the best off-road motorcycle trail ?    \n",
      "1  3             What is Trans Fat? How to reduce that?    \n",
      "2  7                         How many planes Fedex has?    \n",
      "3  7  In the san francisco bay area, does it make se...    \n",
      "4  5           What's the best way to clean a keyboard?    \n",
      "\n",
      "                           or even on some surfaces?  \\\n",
      "0                  long-distance trail throughout CA   \n",
      "1  I heard that tras fat is bad for the body.  Wh...   \n",
      "2  I heard that it is the largest airline in the ...   \n",
      "3  the prices of rent and the price of buying doe...   \n",
      "4  I have very small stuff stuck under my keyboar...   \n",
      "\n",
      "  Optical mice use an LED and a camera to rapidly capture images of the surface beneath the mouse.  The infomation from the camera is analyzed by a DSP (Digital Signal Processor) and used to detect imperfections in the underlying surface and determine motion. Some materials, such as glass, mirrors or other very shiny, uniform surfaces interfere with the ability of the DSP to accurately analyze the surface beneath the mouse.  \\nSince glass is transparent and very uniform, the mouse is unable to pick up enough imperfections in the underlying surface to determine motion.  Mirrored surfaces are also a problem, since they constantly reflect back the same image, causing the DSP not to recognize motion properly. When the system is unable to see surface changes associated with movement, the mouse will not work properly.  \n",
      "0  i hear that the mojave road is amazing!<br />\\...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "1  Trans fats occur in manufactured foods during ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "2  according to the www.fedex.com web site:\\nAir ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "3  renting vs buying depends on your goals. <br /...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "4  There are commercial kits available, but a can...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV (adjust delimiter if needed)\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>What is the best off-road motorcycle trail ? l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is Trans Fat? How to reduce that? I heard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>How many planes Fedex has? I heard that it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>In the san francisco bay area, does it make se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What's the best way to clean a keyboard? I hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399994</th>\n",
       "      <td>2</td>\n",
       "      <td>do all these ads on tv of yoko etc regarding h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399995</th>\n",
       "      <td>6</td>\n",
       "      <td>Ways to sell your video games? Like if you wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399996</th>\n",
       "      <td>2</td>\n",
       "      <td>is it normal to have nots in your breast or bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399997</th>\n",
       "      <td>0</td>\n",
       "      <td>Who can speak Hindi?? If you can write it here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399998</th>\n",
       "      <td>4</td>\n",
       "      <td>where can i find websites  were i can have a v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1399999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class                                               text\n",
       "0            5  What is the best off-road motorcycle trail ? l...\n",
       "1            2  What is Trans Fat? How to reduce that? I heard...\n",
       "2            6  How many planes Fedex has? I heard that it is ...\n",
       "3            6  In the san francisco bay area, does it make se...\n",
       "4            4  What's the best way to clean a keyboard? I hav...\n",
       "...        ...                                                ...\n",
       "1399994      2  do all these ads on tv of yoko etc regarding h...\n",
       "1399995      6  Ways to sell your video games? Like if you wan...\n",
       "1399996      2  is it normal to have nots in your breast or bo...\n",
       "1399997      0  Who can speak Hindi?? If you can write it here...\n",
       "1399998      4  where can i find websites  were i can have a v...\n",
       "\n",
       "[1399999 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the dataset has column names, replace with actual names\n",
    "df.columns = [\"Class\", \"Title\", \"Content\", \"Answer\"]\n",
    "\n",
    "# Combine title and content into a single text field\n",
    "df[\"text\"] = df[\"Title\"].fillna('') + \" \" + df[\"Content\"].fillna('') + \" \" + df[\"Answer\"].fillna('')\n",
    "\n",
    "# Keep only the relevant columns\n",
    "df = df[[\"Class\", \"text\"]]\n",
    "\n",
    "# Convert class labels to zero-based indexing (optional)\n",
    "df[\"Class\"] = df[\"Class\"] - 1  # Convert from 1-10 to 0-9\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error expanding contractions: string index out of range for text: Does anyone work for NATO Ä°zmir/Turkey? Do u know the Human Resources Dept's info to send a resume?Thank you:) My name is Burcu,female,29.Single mom.I live in Ä°zmir/Turkey.I used to live in U.S.A./Newyork, studied Business Administration at the CUNY and worked in an American Logistic company as a Foreign Trade and Freight Specialist at the same time. I also have 10 years of working experience about Export Business worked for several companies in Turkey as well.After my studies and also due to hard times in Newyork(about 9/11), I moved back to Turkey 2 years ago.I stayed in USA about 4 years. As my brother used to worked for NAVY/USA as a peddy officer, I knew the working conditions and benefits therefore I would like to work for NATO/Ä°ZMÄ°R but I don't know how to apply for a job at NATO as a civilian. If anybody knows how to get info for Human Resources dept's postal addresss or tel/fax no's and contact person information please kindly send me an urgent reply. I would be gratefull if you could response my message. \\n\\nTks for kindest reply\\n\\nB.Regards \\nBurcu\\npls, e-mail me buzgoren@yahoo.com goto http://www.nato.int and on the left hand side it says recruitment. click that and that list the current job listings. Good Luck!\n",
      "Error expanding contractions: string index out of range for text: is american english good english? Ä°N ENGLÄ°SH HÄ°STORY lol\n",
      "Error expanding contractions: string index out of range for text: Deatils on Kurdistan Workers Party?  The Kurdistan Workers Party (Kurdish: Partiya KarkerÃªn Kurdistan or PKK), also known as KADEK and Kongra-Gel, is a militant organization, dedicated to creating an independent Kurdish state in a territory (sometimes referenced as Kurdistan) that consists of parts of southeastern Turkey, northeastern Iraq, northeastern Syria and northwestern Iran. Its current ideological foundation is revolutionary Marxism-Leninism and Kurdish nationalism. It is an ethnic secessionist organization using force and threat of force against both civilian and military targets for the purpose of achieving its political goal. The PKK is defined as a terrorist organisation internationally by a number of states and organisations. Also the Kurdish rebel leader of the group, Abdullah Ã–calan, has declared his own guerrillas as \"murderers\".\\n\\nThe PKK emerged as an organization during the 1970s and developed into a formidable paramilitary organisation which rendered much of southeastern Turkey a war zone in the late 1980s and 1990s. Its actions have mainly taken place in Turkey and against Turkish targets in other countries, although it has on occasions co-operated with other Kurdish nationalist paramilitary groups in neighbouring states, such as Iraq and Iran. The PKK argued that its violence was justified by the need to defend Kurds in the context of what it saw as massive cultural suppression of Kurdish identity and cultural rights carried out by governments in the region. However, in its campaign, the PKK has been accused of atrocities against both Turkish and Kurdish civilians. Its actions, along with those of the Turkish state have been criticised by human rights groups such as Amnesty International and Human Rights Watch.\\n\\nThe degree of support for the PKK among Turkish Kurds is disputed. In some of the strongholds of Kurdish nationalism in the Tigris valley and mountainous regions on the Iranian border, PKK-linked parties have consistently polled close to or over 50% of votes cast in elections. However, PKK-linked parties have polled at most approximately one-third of the Kurdish vote (between 5% and 8% of the total Turkish vote), with the majority of Kurds voting for mainstream parties. In some of the more assimilated Kurdish areas, claimed by the PKK as part of 'Kurdistan', support for PKK-linked parties is at 10% or less. There is some electoral support for PKK-linked parties among Kurdish migrants in cities in Western and Southern Turkey such as Adana, Mersin and Ä°zmir. \\n\\nhttp://en.wikipedia.org/wiki/PKK\n",
      "Error expanding contractions: string index out of range for text: the value of a comon class b stock for shawano \"equity oil co-op\".? I need to know the website to go to to find out the value of a common class \"b\" stock for equity oil co-operative in shawano Wi. Ä± AM FÄ°NE WHAT ABOUT YOU\n",
      "Error expanding contractions: string index out of range for text: where is Bilecik?  Bilecik, lying in the green fertile lands of the river valley, is the eastern neighbor of Bursa. Its historical background goes back to 1950 BC, with many civilizations such as Hittites, Phyrigians, Lycians, Persians and Macedonians living here. The province is, worth visiting with its mausoleum of Seyh (Sheik) Edebali, who was an important influential person in the foundation of the Ottoman Empire. Nearby is the mausoleum of Orhan Gazi. Every September, a festival is held in his memory.\\n\\n30 kms from Bilecik is the little town Sogut which got its name from the numerous willows that surround the town. Sogut Is the place where the Ottoman Empire was founded and here there are the life size busts of famous figures of Turkish history. If you would like to see the whole of the history of Turkey before your eyes, then you should visit the Ethnographical Museum. There are many historical tombs and mosques in the province. Onyx handicrafts is recommended as a souvenir from Bilecik of which are great value. \\n\\nBilecik Province\\nFrom Wikipedia, the free encyclopedia\\nJump to: navigation, search\\n\\nLocation of Bilecik ProvinceBilecik is a province in midwest Turkey, neighboring Bursa to the east, Kocaeli and Sakarya to the north, Bolu to the west, EskiÅŸehir to the southeast and KÃ¼tahya to the south, spanning an area of 4,307 kmÂ². Population is 175,500 (1990).\\n\\nHistory\\nThe region was inhabited as early as 3000 BC, and was part of the territory controlled by such notable civilizations as the Hittites (1400-1200 BC), the Phrygians (1200-676 BC), Lydians (595-546 BC), Persians (546-334 BC), Romans (74-395 AD) and Byzantians (395 AD to late 13th century, with two brief occupations by Ummayads in between). The region is also where the Ottoman Empire was founded in 1281, and is the source of important archeological as well as cultural artifacts.\\n\\nBÄ°LECÄ°K\\nGENEL BÄ°LGÄ°LER \\n\\nYÃ¼zÃ¶lÃ§Ã¼mÃ¼: 4.302kmÂ²\\n\\nNÃ¼fus: 194.326\\n\\nÄ°l Trafik No: 11\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nÄ°LÃ‡ELERÄ°N Ä°L MERKEZÄ°NE UZAKLIÄžI; BAZ Ä°LLERÄ°N Ä°LÄ°MÄ°ZE UZAKLIÄžI\\n\\nBozÃ¼yÃ¼k : 34 km EskiÅŸehir : 80 km\\n\\nGÃ¶lpazarÄ± : 44 km KÃ¼tahya : 110 km\\n\\nOsmaneli : 34 km Bursa : 94 km\\n\\nPazaryeri : 30 km Sakarya : 100 km\\n\\nSÃ¶ÄŸÃ¼t : 29 km Ankara : 312 km\\n\\nÄ°nhisar : 56 km Ä°stanbul : 250 km\\n\\nYenipazar : 80 km\n",
      "Error expanding contractions: string index out of range for text: Why is Ä°stanbul called Ä°stanbul?  The Greeks called Constantinople POLI,since it means CITY\\n Even today if you ask a Greek who is going to visit Istanbul where are you going? he will tell you IS TIN POLIN.That means I am going to the CITY.So I think this is the reason it is now called Istanbul\n",
      "Error expanding contractions: string index out of range for text: How do I tell him???!? Umm....Me and my bf have been goin out for about 3 yrs now and last night I was sooo stupid I um kissed another guy....well more than that but I feel sooo bad because I was a virgin and he wanted me to lose my virginity to him and not some other guy.....I know I have to tell him because it just woulden't be right if I kept it from him! How do I tell him I feel sooo bad and I don't know where to begin.... Because you kissed the guy that doesn't mean that you're not a virgin anymore,just decide what you want.Ä°f you love this guy you shouldn't be hanging out with the others.Ä°f you tell him you probably lose him.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from contractions import fix  # Install using: pip install contractions\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Ensure the text is not empty or just whitespace\n",
    "    if not text or text.isspace():\n",
    "        return \"\"  # Return an empty string if the input is invalid\n",
    "    \n",
    "    try:\n",
    "        # Expand contractions (e.g., \"don't\" -> \"do not\")\n",
    "        text = fix(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error expanding contractions: {e} for text: {text}\")\n",
    "        return text  # Return original text if an error occurs\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Tokenize, remove stopwords, and lemmatize\n",
    "    text = \" \".join(lemmatizer.lemmatize(word.strip()) for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the function to the dataset\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "df.to_csv(\"preprocessed_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_train.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"preprocessed_train.csv\")\n",
    "\n",
    "# Ensure columns exist\n",
    "if \"text\" not in df.columns or \"Class\" not in df.columns:\n",
    "    raise ValueError(\"Columns 'text' and 'Class' not found in the CSV file.\")\n",
    "\n",
    "# Drop rows with NaN values in both 'text' and 'Class' columns\n",
    "df = df.dropna(subset=[\"text\", \"Class\"])\n",
    "\n",
    "# Extract features and labels\n",
    "X = df[\"text\"]  # Text data\n",
    "y = df[\"Class\"]  # Target labels\n",
    "\n",
    "# Initialize the vectorizer after data cleaning\n",
    "vectorizer = TfidfVectorizer(max_features=100000)\n",
    "\n",
    "# Proceed with TF-IDF vectorization\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Save the TF-IDF vectorizer model\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "Accuracy: 0.7005900758668971\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57     13964\n",
      "           1       0.72      0.73      0.73     13950\n",
      "           2       0.74      0.80      0.77     13927\n",
      "           3       0.60      0.45      0.51     13975\n",
      "           4       0.82      0.86      0.84     14143\n",
      "           5       0.88      0.84      0.86     14096\n",
      "           6       0.58      0.51      0.54     14237\n",
      "           7       0.69      0.69      0.69     14073\n",
      "           8       0.61      0.81      0.69     13928\n",
      "           9       0.74      0.77      0.75     13689\n",
      "\n",
      "    accuracy                           0.70    139982\n",
      "   macro avg       0.70      0.70      0.70    139982\n",
      "weighted avg       0.70      0.70      0.70    139982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Load the pre-trained TF-IDF vectorizers for train data\n",
    "vectorizer_train = joblib.load(\"tfidf_vectorizer_train.pkl\")\n",
    "\n",
    "# Load the preprocessed training dataset\n",
    "df_train = pd.read_csv(\"preprocessed_train.csv\")\n",
    "\n",
    "# Ensure the 'text' and 'Class' columns exist\n",
    "if \"text\" not in df_train.columns or \"Class\" not in df_train.columns:\n",
    "    raise ValueError(\"Columns 'text' and 'Class' not found in the train CSV file.\")\n",
    "\n",
    "# Drop rows with NaN values in both 'text' and 'Class' columns\n",
    "df_train = df_train.dropna(subset=[\"text\", \"Class\"])\n",
    "\n",
    "# Extract features and labels for training data\n",
    "X_train = df_train[\"text\"]  # Train data text\n",
    "y_train = df_train[\"Class\"]  # Train data labels\n",
    "\n",
    "# Split the training data into a training set and validation set (e.g., 90% train, 10% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=None)\n",
    "\n",
    "# Transform the training and validation data using the corresponding vectorizer\n",
    "X_train_tfidf = vectorizer_train.transform(X_train)\n",
    "X_val_tfidf = vectorizer_train.transform(X_val)\n",
    "\n",
    "# Initialize the model (e.g., Naive Bayes)\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training data (X_train_tfidf and y_train)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "print(\"Validation Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results:\n",
      "Accuracy: 0.7005900758668971\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57     13964\n",
      "           1       0.72      0.73      0.73     13950\n",
      "           2       0.74      0.80      0.77     13927\n",
      "           3       0.60      0.45      0.51     13975\n",
      "           4       0.82      0.86      0.84     14143\n",
      "           5       0.88      0.84      0.86     14096\n",
      "           6       0.58      0.51      0.54     14237\n",
      "           7       0.69      0.69      0.69     14073\n",
      "           8       0.61      0.81      0.69     13928\n",
      "           9       0.74      0.77      0.75     13689\n",
      "\n",
      "    accuracy                           0.70    139982\n",
      "   macro avg       0.70      0.70      0.70    139982\n",
      "weighted avg       0.70      0.70      0.70    139982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Using Logistic Regression for text classification\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
